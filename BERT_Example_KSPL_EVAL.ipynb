{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_Example_KSPL_EVAL.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMS/wdNz90VUCtXiGCD9clI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1dda393cc606404b9d5fd8e27c0676d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0beb6c1db31140b38fbb2b31b4c552a8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1f41927d3e4a4253a3b7f16dcead05de",
              "IPY_MODEL_6f859f2b95ba48c18494f1e7a0d963f5"
            ]
          }
        },
        "0beb6c1db31140b38fbb2b31b4c552a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f41927d3e4a4253a3b7f16dcead05de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6d5a372969144f57bbd7205569df4097",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_18b805b0a0194df2a0650d82e9efc227"
          }
        },
        "6f859f2b95ba48c18494f1e7a0d963f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c5e7716233ec4bdd9b0b780cad001780",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 2.11MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ef5270422e6b4823a066e8c660f743fa"
          }
        },
        "6d5a372969144f57bbd7205569df4097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "18b805b0a0194df2a0650d82e9efc227": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c5e7716233ec4bdd9b0b780cad001780": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ef5270422e6b4823a066e8c660f743fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/margeumkim/BRIDGEMAIL/blob/master/BERT_Example_KSPL_EVAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVRVPbF0W0LW",
        "colab_type": "text"
      },
      "source": [
        "# 1. Loading Pre-Trained BERT\n",
        "\n",
        "\n",
        "Install the pytorch interface for BERT by Hugging Face. (This library contains interfaces for other pretrained language models like OpenAI's GPT and GPT-2.)\n",
        "\n",
        "We've selected the pytorch interface because it strikes a nice balance between the high-level APIs (which are easy to use but don't provide insight into how things work) and tensorflow code (which contains lots of details but often sidetracks us into lessons about tensorflow, when the purpose here is BERT!).\n",
        "\n",
        "If you're running this code on Google Colab, you will have to install this library each time you reconnect; the following cell will take care of that for you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JC5sPrQIXIuK",
        "colab_type": "code",
        "outputId": "d39b6a3c-aac4-4cde-f57b-ed016086119c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n",
            "\u001b[K     |████████████████████████████████| 675kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 14.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 16.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 16.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=861f2d71ae20f03c9b3816400c05d8dc34849c91ec3da48652e3018e0ccf4fa7\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d66nvn-XQ1s",
        "colab_type": "text"
      },
      "source": [
        "Now let's import pytorch, the pretrained BERT model, and a BERT tokenizer.\n",
        "\n",
        "We'll explain the BERT model in detail in a later tutorial, but this is the pre-trained model released by Google that ran for many, many hours on Wikipedia and Book Corpus, a dataset containing +10,000 books of different genres. This model is responsible (with a little modification) for beating NLP benchmarks across a range of tasks. Google released a few variations of BERT models, but the one we'll use here is the smaller of the two available sizes (\"base\" and \"large\") and ignores casing, hence \"uncased.\"\"\n",
        "\n",
        "**transformers** provides a number of classes for applying BERT to different tasks (token classification, text classification, ...). Here, we're using the basic **BertModel** which has no specific output task--it's a good choice for using BERT just to extract embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlhbL_pyXQKA",
        "colab_type": "code",
        "outputId": "495eb8c9-dc1b-4854-e0f8-7fec8da5ffbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "1dda393cc606404b9d5fd8e27c0676d3",
            "0beb6c1db31140b38fbb2b31b4c552a8",
            "1f41927d3e4a4253a3b7f16dcead05de",
            "6f859f2b95ba48c18494f1e7a0d963f5",
            "6d5a372969144f57bbd7205569df4097",
            "18b805b0a0194df2a0650d82e9efc227",
            "c5e7716233ec4bdd9b0b780cad001780",
            "ef5270422e6b4823a066e8c660f743fa"
          ]
        }
      },
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
        "import logging\n",
        "#logging.basicCOnfig(level=logging.INFO)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1dda393cc606404b9d5fd8e27c0676d3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqneXVsRxSt1",
        "colab_type": "text"
      },
      "source": [
        "# 2. Loading Enron emails data \n",
        "We'll load the Enron Emails dataset. For the purpose of exploratory data analysis, I will subset two accounts -- Kate Symes and Phillip Love. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhLzEOgSxr2q",
        "colab_type": "text"
      },
      "source": [
        "Let's import data from my Google drive \n",
        "** (but later, will need to combine with git - you must slice file so that each is <25MB) **\n",
        "\n",
        "> NOTE: When prompted, click on the link to get authentication to allow Google to access your Drive. You should see a screen with “Google Cloud SDK wants to access your Google Account” at the top. After you allow permission, copy the given verification code and paste it in the box in Colab.\n",
        "Once you have completed verification, go to the CSV file in Google Drive, right-click on it and select “Get shareable link”. The link will be copied into your clipboard. Paste this link into a string variable in Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4lrsWfeya7G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "c0fbfe85-08ba-4720-f5fb-8dff126364c4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNzhm56N0y_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "path = \"/content/drive/My Drive/data/emails.csv\"\n",
        "emails_df = pd.read_csv(path)\n",
        "\n",
        "# Dataset is now stored in a Pandas Dataframe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcyCPYVPzng2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "6aded3d4-bd72-47ef-eabc-00c4cba75689"
      },
      "source": [
        "# Checking whether the file is loaded properly\n",
        "print(emails_df.shape)\n",
        "emails_df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(517401, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>allen-p/_sent_mail/1.</td>\n",
              "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>allen-p/_sent_mail/10.</td>\n",
              "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>allen-p/_sent_mail/100.</td>\n",
              "      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>allen-p/_sent_mail/1000.</td>\n",
              "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>allen-p/_sent_mail/1001.</td>\n",
              "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       file                                            message\n",
              "0     allen-p/_sent_mail/1.  Message-ID: <18782981.1075855378110.JavaMail.e...\n",
              "1    allen-p/_sent_mail/10.  Message-ID: <15464986.1075855378456.JavaMail.e...\n",
              "2   allen-p/_sent_mail/100.  Message-ID: <24216240.1075855687451.JavaMail.e...\n",
              "3  allen-p/_sent_mail/1000.  Message-ID: <13505866.1075863688222.JavaMail.e...\n",
              "4  allen-p/_sent_mail/1001.  Message-ID: <30922949.1075863688243.JavaMail.e..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dL4J3ErzvCu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "726ee3c8-2adc-4abc-fd0d-541c52a3b9b3"
      },
      "source": [
        "# A single message looks like this\n",
        "print(emails_df['message'][0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Message-ID: <18782981.1075855378110.JavaMail.evans@thyme>\n",
            "Date: Mon, 14 May 2001 16:39:00 -0700 (PDT)\n",
            "From: phillip.allen@enron.com\n",
            "To: tim.belden@enron.com\n",
            "Subject: \n",
            "Mime-Version: 1.0\n",
            "Content-Type: text/plain; charset=us-ascii\n",
            "Content-Transfer-Encoding: 7bit\n",
            "X-From: Phillip K Allen\n",
            "X-To: Tim Belden <Tim Belden/Enron@EnronXGate>\n",
            "X-cc: \n",
            "X-bcc: \n",
            "X-Folder: \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Sent Mail\n",
            "X-Origin: Allen-P\n",
            "X-FileName: pallen (Non-Privileged).pst\n",
            "\n",
            "Here is our forecast\n",
            "\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dzu4OVOz2mf",
        "colab_type": "text"
      },
      "source": [
        "Let's split the information in each message into different fields."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtXtb0arzz2i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Helper functions\n",
        "def get_text_from_email(msg):\n",
        "    '''To get the content from email objects'''\n",
        "    parts = []\n",
        "    for part in msg.walk():\n",
        "        if part.get_content_type() == 'text/plain':\n",
        "            parts.append( part.get_payload() )\n",
        "    return ''.join(parts)\n",
        "\n",
        "def split_email_addresses(line):\n",
        "    '''To separate multiple email addresses'''\n",
        "    if line:\n",
        "        addrs = line.split(',')\n",
        "        addrs = frozenset(map(lambda x: x.strip(), addrs))\n",
        "    else:\n",
        "        addrs = None\n",
        "    return addrs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qk6c8ZF0zzve",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "0df0e102-2ead-4f0c-aa52-2ae06259d782"
      },
      "source": [
        "import email \n",
        "\n",
        "# Parse the emails into a list email objects\n",
        "messages = list(map(email.message_from_string, emails_df['message']))\n",
        "emails_df.drop('message', axis=1, inplace=True)\n",
        "# Get fields from parsed email objects\n",
        "keys = messages[0].keys()\n",
        "for key in keys:\n",
        "    emails_df[key] = [doc[key] for doc in messages]\n",
        "# Parse content from emails\n",
        "emails_df['content'] = list(map(get_text_from_email, messages))\n",
        "# Split multiple email addresses\n",
        "emails_df['From'] = emails_df['From'].map(split_email_addresses)\n",
        "emails_df['To'] = emails_df['To'].map(split_email_addresses)\n",
        "\n",
        "# Extract the root of 'file' as 'user'\n",
        "emails_df['user'] = emails_df['file'].map(lambda x:x.split('/')[0])\n",
        "del messages\n",
        "\n",
        "emails_df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file</th>\n",
              "      <th>Message-ID</th>\n",
              "      <th>Date</th>\n",
              "      <th>From</th>\n",
              "      <th>To</th>\n",
              "      <th>Subject</th>\n",
              "      <th>Mime-Version</th>\n",
              "      <th>Content-Type</th>\n",
              "      <th>Content-Transfer-Encoding</th>\n",
              "      <th>X-From</th>\n",
              "      <th>X-To</th>\n",
              "      <th>X-cc</th>\n",
              "      <th>X-bcc</th>\n",
              "      <th>X-Folder</th>\n",
              "      <th>X-Origin</th>\n",
              "      <th>X-FileName</th>\n",
              "      <th>content</th>\n",
              "      <th>user</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>allen-p/_sent_mail/1.</td>\n",
              "      <td>&lt;18782981.1075855378110.JavaMail.evans@thyme&gt;</td>\n",
              "      <td>Mon, 14 May 2001 16:39:00 -0700 (PDT)</td>\n",
              "      <td>(phillip.allen@enron.com)</td>\n",
              "      <td>(tim.belden@enron.com)</td>\n",
              "      <td></td>\n",
              "      <td>1.0</td>\n",
              "      <td>text/plain; charset=us-ascii</td>\n",
              "      <td>7bit</td>\n",
              "      <td>Phillip K Allen</td>\n",
              "      <td>Tim Belden &lt;Tim Belden/Enron@EnronXGate&gt;</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>\\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Se...</td>\n",
              "      <td>Allen-P</td>\n",
              "      <td>pallen (Non-Privileged).pst</td>\n",
              "      <td>Here is our forecast\\n\\n</td>\n",
              "      <td>allen-p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>allen-p/_sent_mail/10.</td>\n",
              "      <td>&lt;15464986.1075855378456.JavaMail.evans@thyme&gt;</td>\n",
              "      <td>Fri, 4 May 2001 13:51:00 -0700 (PDT)</td>\n",
              "      <td>(phillip.allen@enron.com)</td>\n",
              "      <td>(john.lavorato@enron.com)</td>\n",
              "      <td>Re:</td>\n",
              "      <td>1.0</td>\n",
              "      <td>text/plain; charset=us-ascii</td>\n",
              "      <td>7bit</td>\n",
              "      <td>Phillip K Allen</td>\n",
              "      <td>John J Lavorato &lt;John J Lavorato/ENRON@enronXg...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>\\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Se...</td>\n",
              "      <td>Allen-P</td>\n",
              "      <td>pallen (Non-Privileged).pst</td>\n",
              "      <td>Traveling to have a business meeting takes the...</td>\n",
              "      <td>allen-p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>allen-p/_sent_mail/100.</td>\n",
              "      <td>&lt;24216240.1075855687451.JavaMail.evans@thyme&gt;</td>\n",
              "      <td>Wed, 18 Oct 2000 03:00:00 -0700 (PDT)</td>\n",
              "      <td>(phillip.allen@enron.com)</td>\n",
              "      <td>(leah.arsdall@enron.com)</td>\n",
              "      <td>Re: test</td>\n",
              "      <td>1.0</td>\n",
              "      <td>text/plain; charset=us-ascii</td>\n",
              "      <td>7bit</td>\n",
              "      <td>Phillip K Allen</td>\n",
              "      <td>Leah Van Arsdall</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>\\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail</td>\n",
              "      <td>Allen-P</td>\n",
              "      <td>pallen.nsf</td>\n",
              "      <td>test successful.  way to go!!!</td>\n",
              "      <td>allen-p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>allen-p/_sent_mail/1000.</td>\n",
              "      <td>&lt;13505866.1075863688222.JavaMail.evans@thyme&gt;</td>\n",
              "      <td>Mon, 23 Oct 2000 06:13:00 -0700 (PDT)</td>\n",
              "      <td>(phillip.allen@enron.com)</td>\n",
              "      <td>(randall.gay@enron.com)</td>\n",
              "      <td></td>\n",
              "      <td>1.0</td>\n",
              "      <td>text/plain; charset=us-ascii</td>\n",
              "      <td>7bit</td>\n",
              "      <td>Phillip K Allen</td>\n",
              "      <td>Randall L Gay</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>\\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail</td>\n",
              "      <td>Allen-P</td>\n",
              "      <td>pallen.nsf</td>\n",
              "      <td>Randy,\\n\\n Can you send me a schedule of the s...</td>\n",
              "      <td>allen-p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>allen-p/_sent_mail/1001.</td>\n",
              "      <td>&lt;30922949.1075863688243.JavaMail.evans@thyme&gt;</td>\n",
              "      <td>Thu, 31 Aug 2000 05:07:00 -0700 (PDT)</td>\n",
              "      <td>(phillip.allen@enron.com)</td>\n",
              "      <td>(greg.piper@enron.com)</td>\n",
              "      <td>Re: Hello</td>\n",
              "      <td>1.0</td>\n",
              "      <td>text/plain; charset=us-ascii</td>\n",
              "      <td>7bit</td>\n",
              "      <td>Phillip K Allen</td>\n",
              "      <td>Greg Piper</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>\\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail</td>\n",
              "      <td>Allen-P</td>\n",
              "      <td>pallen.nsf</td>\n",
              "      <td>Let's shoot for Tuesday at 11:45.</td>\n",
              "      <td>allen-p</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       file  ...     user\n",
              "0     allen-p/_sent_mail/1.  ...  allen-p\n",
              "1    allen-p/_sent_mail/10.  ...  allen-p\n",
              "2   allen-p/_sent_mail/100.  ...  allen-p\n",
              "3  allen-p/_sent_mail/1000.  ...  allen-p\n",
              "4  allen-p/_sent_mail/1001.  ...  allen-p\n",
              "\n",
              "[5 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vUa9S9O74vN",
        "colab_type": "text"
      },
      "source": [
        "Now, select Kate Symes and Phillip Love's account using the \"user\" column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZtz43uG8Cwv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "4f383edf-c834-4a98-cd7f-7fd94e76d4ed"
      },
      "source": [
        "user_list = [\"symes-k\", \"love-p\"]\n",
        "email_address_list = [frozenset({'kate.symes@enron.com'}), frozenset({'phillip.love@enron.com'})]\n",
        "\n",
        "#print (user_list[0])\n",
        "account_i_df = emails_df[emails_df[\"user\"] == user_list[0]].reset_index()\n",
        "account_j_df = emails_df[emails_df[\"user\"] == user_list[1]].reset_index()\n",
        "#ks_pl_emails_df = emails_df[emails_df[\"user\"].isin([\"symes-k\", \"love-p\"])]\n",
        "#account_i_df.head()\n",
        "\n",
        "print (\"number of messages contained in \" + str(user_list[0]) + \"'s account:\" + str(len(account_i_df)) )\n",
        "print (\"number of messages contained in \" + str(user_list[1]) + \"'s account:\" + str(len(account_j_df)) )\n",
        "\n",
        "account_i_sent_df = account_i_df[account_i_df[\"From\"] == email_address_list[0]].reset_index()\n",
        "account_j_sent_df = account_j_df[account_j_df[\"From\"] == email_address_list[1]].reset_index()\n",
        "\n",
        "print (\"number of sent messages contained in \" + str(user_list[0]) + \"'s account:\" + str(len(account_i_sent_df)) )\n",
        "print (\"number of sent messages contained in \" + str(user_list[1]) + \"'s account:\" + str(len(account_j_sent_df)) )\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of messages contained in symes-k's account:10827\n",
            "number of messages contained in love-p's account:5002\n",
            "number of sent messages contained in symes-k's account:5177\n",
            "number of sent messages contained in love-p's account:3100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwL4RnsZ9P96",
        "colab_type": "text"
      },
      "source": [
        "Select contents and for each person"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-Sfytyx-G3t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#content_i_df = account_i_df[\"content\"].reset_index()\n",
        "#content_i_df.head()\n",
        "#content_j_df = account_j_df[\"content\"].reset_index()\n",
        "#content_j_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SzhnhbL-YUi",
        "colab_type": "text"
      },
      "source": [
        "Pre-process text content:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BneABW8--wO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def email_clean(text):\n",
        "    text = text.rstrip().lower()\n",
        "    text = \" \".join([i for i in text.split() if(not i.isdigit())])\n",
        "    text = re.sub(r'\\n--.*?\\n', '', text, flags=re.DOTALL)\n",
        "    text = re.sub(r'Forwarded by.*?Subject:', '', text, flags=re.DOTALL) \n",
        "    text = re.sub(r'Fwd:.*?Subject:', '', text, flags=re.DOTALL) \n",
        "    text = re.sub(r'Fw:.*?Subject:', '', text, flags=re.DOTALL)     \n",
        "    text = re.sub(r'FW:.*?Subject:', '', text, flags=re.DOTALL)         \n",
        "    text = re.sub(r'Forwarded:.*?Subject:', '', text, flags=re.DOTALL)         \n",
        "    text = re.sub(r'From:.*?Subject:', '', text, flags=re.DOTALL)\n",
        "    text = re.sub(r'PM', '', text, flags=re.DOTALL)\n",
        "    text = re.sub(r'AM', '', text, flags=re.DOTALL)\n",
        "    text = re.sub(r'enron america corp', '', text, flags=re.DOTALL)\n",
        "    text = re.sub(r'enron', '', text, flags=re.DOTALL)    \n",
        "    text = re.sub(r'etc', '', text, flags=re.DOTALL)    \n",
        "    text = re.sub(r'\\n', '', text, flags=re.DOTALL)    \n",
        "    text = re.sub(r'.*?@.*?', '', text, flags=re.DOTALL)\n",
        "    text = re.sub(r'http://.*?', '', text, flags=re.DOTALL)    \n",
        "#    text = re.sub(signoff_1, '', text, flags=re.DOTALL)    \n",
        "#    text = re.sub(signoff_2, '', text, flags=re.DOTALL)       \n",
        "    text = re.sub(signoff_3, '', text, flags=re.DOTALL)   \n",
        "    return text\n",
        "\n",
        "\n",
        "def clean(text):\n",
        "#    stop = set(stopwords.words('english'))\n",
        "#    stop.update((\"to\",\"cc\",\"subject\",\"http\",\"from\",\"sent\",\n",
        "#                 \"aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\", \n",
        "#                 \"enron america corp\", \"enron\", \"etc\", \"na\", signoff_1, signoff_2, signoff_3))\n",
        "    exclude = set(string.punctuation) - {'.'}\n",
        "    lemma = WordNetLemmatizer()\n",
        "    porter= PorterStemmer()\n",
        "    \n",
        "#    text = text.rstrip().lower()\n",
        "    digit_free = \" \".join([i for i in text.lower().split() if(not i.isdigit())])\n",
        "    punc_free = ''.join(ch for ch in digit_free if ch not in exclude)\n",
        "#    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free)\n",
        "    #stem = \" \".join(porter.stem(token) for token in normalized.split())\n",
        "    \n",
        "    return punc_free\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzglQNly-x7f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "257d5b24-2e11-4799-df71-872637a780b8"
      },
      "source": [
        "#import nltk\n",
        "#nltk.download('stopwords')\n",
        "#nltk.download('wordnet')\n",
        "\n",
        "import re\n",
        "#from nltk.corpus import stopwords \n",
        "#from nltk.stem.wordnet import WordNetLemmatizer\n",
        "#import string\n",
        "#from nltk.stem.porter import PorterStemmer \n",
        "\n",
        "\n",
        "#signoff_1 = str(account_i_df[\"user\"][0].split('-')[1] + list(account_i_df[\"user\"][0].split('-')[0])[0])\n",
        "#print(signoff_1)\n",
        "#signoff_2 = str(list(signoff_1)[0])\n",
        "#print(signoff_2)\n",
        "signoff_3 = str(account_i_sent_df[\"user\"][0].split('-')[0])\n",
        "print(signoff_3)\n",
        "\n",
        "account_i_clean_content =[]\n",
        "for text in account_i_sent_df['content']:\n",
        "    account_i_clean_content.append(email_clean(text).split('.'))\n",
        "#    account_i_clean_content.append(clean(email_clean(text)))\n",
        "\n",
        "#signoff_1 = str(account_j_df[\"user\"][0].split('-')[1] + list(account_j_df[\"user\"][0].split('-')[0])[0])\n",
        "#print(signoff_1)\n",
        "#signoff_2 = str(list(signoff_1)[0])\n",
        "#print(signoff_2)\n",
        "signoff_3 = str(account_j_sent_df[\"user\"][0].split('-')[0])\n",
        "print(signoff_3)\n",
        "\n",
        "account_j_clean_content = []\n",
        "for text in account_j_sent_df['content']:\n",
        "    account_j_clean_content.append(email_clean(text).split('.')) \n",
        "#    account_j_clean_content.append(clean(email_clean(text)))\n",
        "\n",
        "# Flattening nested lists\n",
        "account_i_content = [] \n",
        "for text in account_i_clean_content:\n",
        "    for item in text:\n",
        "      if len(list(item.split())) >3: \n",
        "        if len(list(item.split())) < 101: \n",
        "          account_i_content.append(item)\n",
        "\n",
        "account_j_content = [] \n",
        "for text in account_j_clean_content:\n",
        "    for item in text:\n",
        "      if len(list(item.split())) >3: \n",
        "        if len(list(item.split())) < 101: \n",
        "          account_j_content.append(item)      "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "symes\n",
            "love\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiYEWClBbAMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create labels \n",
        "#account_i_content = pd.DataFrame(account_i_content)\n",
        "#account_i_content.loc[account_i_content.label==0]\n",
        "#df.loc[df.label == 0].sample(5)[['sentence', 'label']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yenB06gCXnSS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "outputId": "2ef8eaa7-656c-485e-d410-3d55856c72cc"
      },
      "source": [
        "print(account_j_content[4])\n",
        "len(list(account_j_content[4].split()))\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "net > subject: the chicken > > why did the chicken cross the road? > > vice president gore > i fight for the chickens and i am fighting for the chickens right > now\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-dd64b8224db1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Update the maximum sentence length.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mmax_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Max sentence length: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PznC5T1pdTjE",
        "colab_type": "text"
      },
      "source": [
        "# 3. Tokenization & Input Formatting\n",
        "Because BERT is a pretrained model that expects input data in a specific format, we will need:\n",
        "\n",
        "1. A **special token**, [SEP], to mark the end of a sentence, or the separation between two sentences\n",
        "2. A **special token**, [CLS], at the beginning of our text. This token is used for classification tasks, but BERT expects it no matter what your application is.\n",
        "3. Tokens that conform with the fixed vocabulary used in BERT\n",
        "4. The **Token IDs** for the tokens, from BERT's tokenizer\n",
        "5. **Mask IDs** to indicate which elements in the sequence are tokens and which are padding elements\n",
        "6. **Segment IDs** used to distinguish different sentences\n",
        "7. **Positional Embeddings** used to show token position within the sequence\n",
        "Luckily, the transformers interface takes care of all of the above requirements (using the tokenizer.encode_plus function).\n",
        "\n",
        "Since this is intended as an introduction to working with BERT, though, we're going to perform these steps in a (mostly) manual way.\n",
        "\n",
        "For an example of using tokenizer.encode_plus, see the next post on Sentence Classification [here](http://mccormickml.com/2019/07/22/BERT-fine-tuning/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aynvBYCleFTH",
        "colab_type": "text"
      },
      "source": [
        "##3.1. BERT Tokenizer\n",
        "To feed our text to BERT, it must be split into tokens, and then these tokens must be mapped to their index in the tokenizer vocabulary.\n",
        "\n",
        "The tokenization must be performed by the tokenizer included with BERT--the below cell will download this for us. We'll be using the \"uncased\" version here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxLm5Qb4YhzL",
        "colab_type": "code",
        "outputId": "09f2f31a-fbab-4437-ea91-bb178e94dd94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNhnF1kUeinf",
        "colab_type": "text"
      },
      "source": [
        "Le'ts apply the tokenizer to one sentence just to see the output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e0lfdv6FCHs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "033c8840-dd8c-4582-d8a7-9162559a0f5d"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', account_j_content[1])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(account_j_content[1]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(account_j_content[1])))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:   make me a plate, remember i have a basketball game, so i will be home about 10:30\n",
            "Tokenized:  ['make', 'me', 'a', 'plate', ',', 'remember', 'i', 'have', 'a', 'basketball', 'game', ',', 'so', 'i', 'will', 'be', 'home', 'about', '10', ':', '30']\n",
            "Token IDs:  [2191, 2033, 1037, 5127, 1010, 3342, 1045, 2031, 1037, 3455, 2208, 1010, 2061, 1045, 2097, 2022, 2188, 2055, 2184, 1024, 2382]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syJqBhZKe3S9",
        "colab_type": "text"
      },
      "source": [
        "When we actually convert all of our sentences, we'll use the tokenize.encode function to handle both steps, rather than calling tokenize and convert_tokens_to_ids separately.\n",
        "\n",
        "Before we can do that, though, we need to talk about some of BERT's formatting requirements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_OcHWoNfSp_",
        "colab_type": "text"
      },
      "source": [
        "## 3.2. Required Formatting\n",
        "\n",
        "The above code left out a few required formatting steps that we'll look at here.\n",
        "\n",
        "Side Note: The input format to BERT seems \"over-specified\" to me... We are required to give it a number of pieces of information which seem redundant, or like they could easily be inferred from the data without us explicity providing it. But it is what it is, and I suspect it will make more sense once I have a deeper understanding of the BERT internals.\n",
        "\n",
        "We are required to:\n",
        "\n",
        "1. Add special tokens to the start and end of each sentence.\n",
        "2. Pad & truncate all sentences to a single constant length.\n",
        "3. Explicitly differentiate real tokens from padding tokens with the \"attention mask\".\n",
        "\n",
        "#### Special tokens\n",
        "* [SEP] at the end of every sentence\n",
        "* [CLS] for classification tasks -- the beginning of every sentence.\n",
        "\n",
        "#### Sentence Length & Attention Mask\n",
        "The sentences in our dataset obviously have varying lengths, so how does BERT handle this?\n",
        "\n",
        "BERT has two constraints:\n",
        "\n",
        "1. All sentences must be padded or truncated to a single, fixed length.\n",
        "2. The maximum sentence length is 512 tokens.\n",
        "\n",
        "Padding is done with a special [PAD] token, which is at index 0 in the BERT vocabulary. The below illustration demonstrates padding out to a \"MAX_LEN\" of 8 tokens.\n",
        "\n",
        "The \"Attention Mask\" is simply an array of 1s and 0s indicating which tokens are padding and which aren't (seems kind of redundant, doesn't it?!). This mask tells the \"Self-Attention\" mechanism in BERT not to incorporate these PAD tokens into its interpretation of the sentence.\n",
        "\n",
        "The maximum length does impact training and evaluation speed, however. For example, with a Tesla K80:\n",
        "\n",
        "MAX_LEN = 128 --> Training epochs take ~5:28 each\n",
        "\n",
        "MAX_LEN = 64 --> Training epochs take ~2:57 each"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiaY0Rl6ZrdT",
        "colab_type": "text"
      },
      "source": [
        "## 3.3 Tokenize Dataset\n",
        "The transformers library provides a helpful encode function which will handle most of the parsing and data prep steps for us.\n",
        "\n",
        "Before we are ready to encode our text, though, we need to decide on a maximum sentence length for padding / truncating to.\n",
        "\n",
        "The below cell will perform one tokenization pass of the dataset in order to measure the maximum sentence length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akPXsSttZvHH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a87a5287-0189-4e38-a9f8-4029f9df0d8a"
      },
      "source": [
        "max_len = 0\n",
        "\n",
        "# For every sentence...\n",
        "for sent in account_j_content:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_len)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nENDqtifaFbX",
        "colab_type": "text"
      },
      "source": [
        "As there are some longer test sentences, I'll set the maximum length to 500.\n",
        "\n",
        "Now we're ready to perform the real tokenization.\n",
        "\n",
        "The tokenizer.encode_plus function combines multiple steps for us:\n",
        "\n",
        "1. Split the sentence into tokens.\n",
        "2. Add the special [CLS] and [SEP] tokens.\n",
        "3. Map the tokens to their IDs.\n",
        "4. Pad or truncate all sentences to the same length.\n",
        "5. Create the attention masks which explicitly differentiate real tokens from [PAD] tokens.\n",
        "\n",
        "The first four features are in tokenizer.encode, but I'm using tokenizer.encode_plus to get the fifth item (attention masks). Documentation is [here](https://huggingface.co/transformers/main_classes/tokenizer.html?highlight=encode_plus#transformers.PreTrainedTokenizer.encode_plus)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yHWEcD5aW_m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "0a5532fc-b0fb-401b-8a5d-848b43046ff3"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in account_j_content:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 400,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "token_tensor = torch.cat(input_ids, dim=0)\n",
        "attention_masks_tensor = torch.cat(attention_masks, dim=0)\n",
        "#labels = torch.tensor(labels)  # currently, not using labels (won't evaluate it... using just pre-trained model)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', account_i_content[2])\n",
        "print('Token IDs:', token_tensor[2])\n",
        "\n",
        "# started running 12:08"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  i've entered the following imbalance deals under stca and stwbom desks\n",
            "Token IDs: tensor([  101, 20228,   102,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YdfCtP-gjtG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "43b77b21-e032-402a-c636-8ba11f90c09c"
      },
      "source": [
        "print (len(attention_masks_tensor)) #73725 sentences for Kate Symes  #42121 sentences for Phillip Love\n",
        "# after subsetting into sent mails, 18865 sentences for Phillip Love\n",
        "print (len(token_tensor[2]))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18865\n",
            "400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7IBEE1Jg-T8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_segments(tokens, max_seq_length):\n",
        "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
        "    if len(tokens)>max_seq_length:\n",
        "        raise IndexError(\"Token length more than max seq length!\")\n",
        "    segments = []\n",
        "    current_segment_id = 0\n",
        "    for token in tokens:\n",
        "        segments.append(current_segment_id)\n",
        "        if token == \"[SEP]\":\n",
        "            current_segment_id = 1\n",
        "    return segments + [0] * (max_seq_length - len(tokens))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvodT7z1hjMY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "7edaa1b0-64f9-4586-b19b-2e16d8f9c757"
      },
      "source": [
        "segment_ids = get_segments(token_tensor, 500) "
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-148-7e57a673da73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msegment_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_segments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-147-51e936c5a624>\u001b[0m in \u001b[0;36mget_segments\u001b[0;34m(tokens, max_seq_length)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mmax_seq_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Token length more than max seq length!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0msegments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcurrent_segment_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Token length more than max seq length!"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgjpCdEHfwP2",
        "colab_type": "text"
      },
      "source": [
        "# 4. Extracting Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OB9FeKRwfyhO",
        "colab_type": "text"
      },
      "source": [
        "## 4.1. Running BERT on our text\n",
        "Next we need to convert our data to torch tensors and call the BERT model. The BERT PyTorch interface requires that the data be in torch tensors rather than Python lists, so we convert the lists here - this does not change the shape or the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UENYAez7gFje",
        "colab_type": "text"
      },
      "source": [
        "Calling from_pretrained will fetch the model from the internet. When we load the bert-base-uncased, we see the definition of the model printed in the logging. The model is a deep neural network with 12 layers! Explaining the layers and their functions is outside the scope of this post, and you can skip over this output for now.\n",
        "\n",
        "model.eval() puts our model in evaluation mode as opposed to training mode. In this case, evaluation mode turns off dropout regularization which is used in training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Alk4SwcgJWY",
        "colab_type": "code",
        "outputId": "6e362e1b-2064-4980-afa1-868c8aa9a025",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Load pre-trained model (weights)\n",
        "model = BertModel.from_pretrained('bert-base-uncased',\n",
        "                                  output_hidden_states = True, # whether the model returns all hidden-states.\n",
        "                                  )\n",
        "\n",
        "# Put the model in \"evaluation\" mode, meaning feed-forward operation\n",
        "model.eval()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qk0pfcc6oojt",
        "colab_type": "text"
      },
      "source": [
        "Next, let's evaluate BERT on our text in each account, and fetch the hidden states of the network!\n",
        "\n",
        "> Side note: torch.no_grad tells PyTorch not to construct the compute graph during this forward pass (since we won't be running backprop here)--this just reduces memory consumption and speeds things up a little."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jKEdtaLop0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run the text through BERT, and collect all of the hidden states produced\n",
        "# from all 12 layers. \n",
        "with torch.no_grad():\n",
        "\n",
        "    outputs = model(token_tensor)   # currently, ignoring the segment tensor\n",
        "\n",
        "    # Evaluating the model will return a different number of objects based on \n",
        "    # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
        "    # becase we set `output_hidden_states = True`, the third item will be the \n",
        "    # hidden states from all layers. See the documentation for more details:\n",
        "    # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
        "    hidden_states = outputs[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzXlGzzMo8GI",
        "colab_type": "text"
      },
      "source": [
        "## 3.2. Understanding the Output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fB3-VFKLo-lz",
        "colab_type": "text"
      },
      "source": [
        "The full set of hidden states for this model, stored in the object hidden_states, is a little dizzying. This object has four dimensions, in the following order:\n",
        "\n",
        "1. The layer number (13 layers)\n",
        "2. The batch number (1 sentence)\n",
        "3. The word / token number (22 tokens in our sentence)\n",
        "4. The hidden unit / feature number (768 features)\n",
        "\n",
        "Wait, 13 layers? Doesn't BERT only have 12? It's 13 because the first element is the input embeddings, the rest is the outputs of each of BERT's 12 layers.\n",
        "\n",
        "That’s 219,648 unique values just to represent our one sentence!\n",
        "\n",
        "The second dimension, the batch size, is used when submitting multiple sentences to the model at once; here, though, we just have one example sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zvr6YWupwGp",
        "colab_type": "code",
        "outputId": "eb3e52df-b2dc-47b1-839a-df96b58ee326",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print (\"Number of layers:\", len(hidden_states), \"  (initial embeddings + 12 BERT layers)\")\n",
        "layer_i = 0\n",
        "\n",
        "print (\"Number of batches:\", len(hidden_states[layer_i]))\n",
        "batch_i = 0\n",
        "\n",
        "print (\"Number of tokens:\", len(hidden_states[layer_i][batch_i]))\n",
        "token_i = 0\n",
        "\n",
        "print (\"Number of hidden units:\", len(hidden_states[layer_i][batch_i][token_i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of layers: 13   (initial embeddings + 12 BERT layers)\n",
            "Number of batches: 1\n",
            "Number of tokens: 22\n",
            "Number of hidden units: 768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyUv6FApp1MQ",
        "colab_type": "text"
      },
      "source": [
        "Let's take a quick look at the range of values for a given layer and token.\n",
        "\n",
        "You'll find that the range is fairly similar for all layers and tokens, with the majority of values falling between [-2, 2], and a small smattering of values around -10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ii8lXaACp4KU",
        "colab_type": "code",
        "outputId": "046e7756-8036-4ac0-9156-58b354f993a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        }
      },
      "source": [
        "# For the 5th token in our sentence, select its feature values from layer 5.\n",
        "token_i = 10    # 6 and 10 are bank\n",
        "layer_i = 12\n",
        "vec = hidden_states[layer_i][batch_i][token_i]\n",
        "\n",
        "print (tokenized_text[token_i]) \n",
        "\n",
        "# Plot the values as a histogram to show their distribution.\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.hist(vec, bins=200)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bank\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNg4tbz8rhbL",
        "colab_type": "text"
      },
      "source": [
        "Grouping the values by layer makes sense for the model, but for our purposes we want it grouped by token.\n",
        "\n",
        "Current dimensions:\n",
        "\n",
        "[# layers, # batches, # tokens, # features]\n",
        "\n",
        "Desired dimensions:\n",
        "\n",
        "[# tokens, # layers, # features]\n",
        "\n",
        "Luckily, PyTorch includes the permute function for easily rearranging the dimensions of a tensor.\n",
        "\n",
        "However, the first dimension is currently a Python list!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYB-AkZlrgAd",
        "colab_type": "code",
        "outputId": "c89be9da-5c8a-485e-c1c3-24e8b1d22d78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# `hidden_states` is a Python list.\n",
        "print('      Type of hidden_states: ', type(hidden_states))\n",
        "\n",
        "# Each layer in the list is a torch tensor.\n",
        "print('Tensor shape for each layer: ', hidden_states[0].size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Type of hidden_states:  <class 'tuple'>\n",
            "Tensor shape for each layer:  torch.Size([1, 22, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-xgzS2LryXG",
        "colab_type": "text"
      },
      "source": [
        "Let's combine the layers to make this one whole big tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10EYBipsr0mT",
        "colab_type": "code",
        "outputId": "9f04b5f5-b0f5-4f06-a904-d6ec2da2c9e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Concatenate the tensors for all layers. We use `stack` here to\n",
        "# create a new dimension in the tensor.\n",
        "token_embeddings = torch.stack(hidden_states, dim=0)\n",
        "\n",
        "token_embeddings.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([13, 1, 22, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJdLOE7wr4HN",
        "colab_type": "text"
      },
      "source": [
        "Let's get rid of the \"batches\" dimension since we don't need it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uj0_LphRr6j9",
        "colab_type": "code",
        "outputId": "ebc990e6-2bab-44b7-d81d-f00b80902f38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Remove dimension 1, the \"batches\".\n",
        "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "\n",
        "token_embeddings.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([13, 22, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZFNQCQEr_q-",
        "colab_type": "text"
      },
      "source": [
        "Finally, we can switch around the \"layers\" and \"tokens\" dimensions with permute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAiwKZI3sAqu",
        "colab_type": "code",
        "outputId": "eb765204-b99c-4285-ec09-ef00f29dc14d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Swap dimensions 0 and 1.\n",
        "token_embeddings = token_embeddings.permute(1,0,2)\n",
        "\n",
        "token_embeddings.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([22, 13, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaRCIIqzsDIE",
        "colab_type": "text"
      },
      "source": [
        "##3.3. Creating word and sentence vectors from hidden states"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55KOhfKIKG0r",
        "colab_type": "text"
      },
      "source": [
        "### Word Vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9mspiRtsHQH",
        "colab_type": "text"
      },
      "source": [
        "Now, what do we do with these hidden states? We would like to get individual vectors for each of our tokens, or perhaps a single vector representation of the whole sentence, but for each token of our input we have 13 separate vectors each of length 768.\n",
        "\n",
        "In order to get the individual vectors we will need to combine some of the layer vectors...but which layer or combination of layers provides the best representation?\n",
        "\n",
        "Unfortunately, there's no single easy answer... Let's try a couple reasonable approaches, though. Afterwards, I'll point you to some helpful resources which look into this question further."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIpgwR0KsQ1C",
        "colab_type": "text"
      },
      "source": [
        "Word Vectors\n",
        "To give you some examples, let's create word vectors two ways.\n",
        "\n",
        "First, let's **concatenate** the last four layers, giving us a single word vector per token. Each vector will have length 4 x 768 = 3,072."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAyPKoNgsQMC",
        "colab_type": "code",
        "outputId": "122c0938-1f4f-4ebd-db21-47e098fb64a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Stores the token vectors, with shape [22 x 3,072]\n",
        "token_vecs_cat = []\n",
        "\n",
        "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
        "\n",
        "# For each token in the sentence...\n",
        "for token in token_embeddings:\n",
        "    \n",
        "    # `token` is a [12 x 768] tensor\n",
        "\n",
        "    # Concatenate the vectors (that is, append them together) from the last \n",
        "    # four layers.\n",
        "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
        "    cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
        "    \n",
        "    # Use `cat_vec` to represent `token`.\n",
        "    token_vecs_cat.append(cat_vec)\n",
        "\n",
        "print ('Shape is: %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape is: 22 x 3072\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMG9-694Jlyu",
        "colab_type": "text"
      },
      "source": [
        "As an alternative method, let's try creating the word vectors by **summing** together the last four layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xx_BEglpJqxE",
        "colab_type": "code",
        "outputId": "dbe253d3-4e0d-470f-8efb-e96e7a353aba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Stores the token vectors, with shape [22 x 768]\n",
        "token_vecs_sum = []\n",
        "\n",
        "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
        "\n",
        "# For each token in the sentence...\n",
        "for token in token_embeddings:\n",
        "\n",
        "    # `token` is a [12 x 768] tensor\n",
        "\n",
        "    # Sum the vectors from the last four layers.\n",
        "    sum_vec = torch.sum(token[-4:], dim=0)\n",
        "    \n",
        "    # Use `sum_vec` to represent `token`.\n",
        "    token_vecs_sum.append(sum_vec)\n",
        "\n",
        "print ('Shape is: %d x %d' % (len(token_vecs_sum), len(token_vecs_sum[0])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape is: 22 x 768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5E4dtcQeJ-2z",
        "colab_type": "text"
      },
      "source": [
        "### Sentence Vectors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjF90A6xKLI0",
        "colab_type": "text"
      },
      "source": [
        "To get a single vector for our entire sentence we have multiple application-dependent strategies, but a simple approach is to average the second to last hiden layer of each token producing a single 768 length vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPqFFBr0KJyB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# `hidden_states` has shape [13 x 1 x 22 x 768]\n",
        "\n",
        "# `token_vecs` is a tensor with shape [22 x 768]\n",
        "token_vecs = hidden_states[-2][0]\n",
        "\n",
        "# Calculate the average of all 22 token vectors.\n",
        "sentence_embedding = torch.mean(token_vecs, dim=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwZjtE3ZKPZB",
        "colab_type": "code",
        "outputId": "ad565b7f-ac94-487a-fb26-c23398ad3d79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print (\"Our final sentence embedding vector of shape:\", sentence_embedding.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our final sentence embedding vector of shape: torch.Size([768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXTKJnb_KSgp",
        "colab_type": "text"
      },
      "source": [
        "##3.4. Confirming contextually dependent vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQN5w6zgKXiL",
        "colab_type": "text"
      },
      "source": [
        "To confirm that the value of these vectors are in fact contextually dependent, let's look at the different instances of the word \"bank\" in our example sentence:\n",
        "\n",
        "\"After stealing money from the **bank vault**, the **bank robber** was seen fishing on the **Mississippi river bank**.\"\n",
        "\n",
        "Let's find the index of those three instances of the word \"bank\" in the example sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iL4OmJfSKh-w",
        "colab_type": "code",
        "outputId": "001a1e14-851b-472d-d487-66422867f628",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "for i, token_str in enumerate(tokenized_text):\n",
        "  print (i, token_str)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 [CLS]\n",
            "1 after\n",
            "2 stealing\n",
            "3 money\n",
            "4 from\n",
            "5 the\n",
            "6 bank\n",
            "7 vault\n",
            "8 ,\n",
            "9 the\n",
            "10 bank\n",
            "11 robber\n",
            "12 was\n",
            "13 seen\n",
            "14 fishing\n",
            "15 on\n",
            "16 the\n",
            "17 mississippi\n",
            "18 river\n",
            "19 bank\n",
            "20 .\n",
            "21 [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQ9I9Z8qKlbc",
        "colab_type": "text"
      },
      "source": [
        "They are at 6, 10, and 19.\n",
        "\n",
        "For this analysis, we'll use the word vectors that we created by summing the last four layers.\n",
        "\n",
        "We can try printing out their vectors to compare them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sk0ZviYPKpb6",
        "colab_type": "code",
        "outputId": "c92f125a-fca6-4c06-cb65-5bf35790a8f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print('First 5 vector values for each instance of \"bank\".')\n",
        "print('')\n",
        "print(\"bank vault   \", str(token_vecs_sum[6][:5]))\n",
        "print(\"bank robber  \", str(token_vecs_sum[10][:5]))\n",
        "print(\"river bank   \", str(token_vecs_sum[19][:5]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First 5 vector values for each instance of \"bank\".\n",
            "\n",
            "bank vault    tensor([ 3.3596, -2.9805, -1.5421,  0.7065,  2.0031])\n",
            "bank robber   tensor([ 2.7359, -2.5577, -1.3094,  0.6797,  1.6633])\n",
            "river bank    tensor([ 1.5266, -0.8895, -0.5152, -0.9298,  2.8334])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bw8qk5kvKoON",
        "colab_type": "text"
      },
      "source": [
        "We can see that the values differ, but let's calculate the cosine similarity between the vectors to make a more precise comparison.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BxO4s6RK0Ps",
        "colab_type": "code",
        "outputId": "81237668-13c7-4b08-ab84-fb14c71e6dcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# Calculate the cosine similarity between the word bank \n",
        "# in \"bank robber\" vs \"river bank\" (different meanings).\n",
        "diff_bank = 1 - cosine(token_vecs_sum[10], token_vecs_sum[19])\n",
        "\n",
        "# Calculate the cosine similarity between the word bank\n",
        "# in \"bank robber\" vs \"bank vault\" (same meaning).\n",
        "same_bank = 1 - cosine(token_vecs_sum[10], token_vecs_sum[6])\n",
        "\n",
        "print('Vector similarity for  *similar*  meanings:  %.2f' % same_bank)\n",
        "print('Vector similarity for *different* meanings:  %.2f' % diff_bank)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vector similarity for  *similar*  meanings:  0.94\n",
            "Vector similarity for *different* meanings:  0.69\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}